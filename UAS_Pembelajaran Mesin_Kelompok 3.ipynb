{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi Penerimaan Murid Prasekolah menggunakan Support Vector Machine (SVM) dan Neural Network (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KELOMPOK 3\n",
    "- 2210511046 Hanifah Az-Zahra\n",
    "- 2210511054 Dinda Cantika Putri\n",
    "- 2210511070 Choirunnisa Zalfaa Nabilah\n",
    "- 2210511072 Edwina Martha Putri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 9.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 11.5 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 12.9/12.9 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "     -------------------------------------- 508.0/508.0 KB 8.0 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "     ------------------------------------- 346.6/346.6 KB 10.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "     -------------------------------------- 390.0/390.0 MB 4.3 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.12.1-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 10.6 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 10.6 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 11.8 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.9/71.9 KB 2.0 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-5.29.0-cp310-abi3-win_amd64.whl (434 kB)\n",
      "     -------------------------------------- 434.5/434.5 KB 4.5 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.68.0-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "     ---------------------------------------- 4.4/4.4 MB 9.7 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.7/133.7 KB 4.0 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     ---------------------------------------- 26.4/26.4 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\acer\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "     -------------------------------------- 126.6/126.6 KB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 9.7 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "     ---------------------------------------- 15.9/15.9 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.9/64.9 KB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\acer\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 KB ? eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (58.1.0)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "     ---------------------------------------- 44.8/44.8 MB 4.3 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     -------------------------------------- 301.8/301.8 KB 4.7 MB/s eta 0:00:00\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "     ---------------------------------------- 72.5/72.5 KB 2.0 MB/s eta 0:00:00\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "     -------------------------------------- 242.4/242.4 KB 3.7 MB/s eta 0:00:00\n",
      "Collecting optree\n",
      "  Downloading optree-0.13.1-cp310-cp310-win_amd64.whl (282 kB)\n",
      "     -------------------------------------- 282.7/282.7 KB 3.5 MB/s eta 0:00:00\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "     -------------------------------------- 167.3/167.3 KB 5.1 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.4/70.4 KB 3.8 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "     -------------------------------------- 102.2/102.2 KB 5.7 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.3/126.3 KB 3.6 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "     -------------------------------------- 106.3/106.3 KB 6.0 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "     -------------------------------------- 224.5/224.5 KB 6.9 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 KB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acer\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, wheel, urllib3, tzdata, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, joblib, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, scipy, requests, pandas, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, scikit-learn, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.8.30 charset-normalizer-3.4.0 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 h5py-3.12.1 idna-3.10 joblib-1.4.2 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 pandas-2.2.3 protobuf-5.29.0 pytz-2024.2 requests-2.32.3 rich-13.9.4 scikit-learn-1.5.2 scipy-1.14.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 threadpoolctl-3.5.0 tzdata-2024.2 urllib3-2.2.3 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas tensorflow scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parents has_nurs      form children     housing     finance         social  \\\n",
       "0   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "1   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "2   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "3   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "4   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "\n",
       "        health      class  \n",
       "0  recommended  recommend  \n",
       "1     priority   priority  \n",
       "2    not_recom  not_recom  \n",
       "3  recommended  recommend  \n",
       "4     priority   priority  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menambahkan header\n",
    "headers = [\"parents\", \"has_nurs\", \"form\", \"children\", \"housing\", \"finance\", \"social\", \"health\", \"class\"]\n",
    "df = pd.read_csv('nursery/nursery.data', names=headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4320</td>\n",
       "      <td>2592</td>\n",
       "      <td>3240</td>\n",
       "      <td>3240</td>\n",
       "      <td>4320</td>\n",
       "      <td>6480</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       parents has_nurs      form children     housing     finance   social  \\\n",
       "count    12960    12960     12960    12960       12960       12960    12960   \n",
       "unique       3        5         4        4           3           2        3   \n",
       "top      usual   proper  complete        1  convenient  convenient  nonprob   \n",
       "freq      4320     2592      3240     3240        4320        6480     4320   \n",
       "\n",
       "             health      class  \n",
       "count         12960      12960  \n",
       "unique            3          5  \n",
       "top     recommended  not_recom  \n",
       "freq           4320       4320  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12960 entries, 0 to 12959\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   parents   12960 non-null  object\n",
      " 1   has_nurs  12960 non-null  object\n",
      " 2   form      12960 non-null  object\n",
      " 3   children  12960 non-null  object\n",
      " 4   housing   12960 non-null  object\n",
      " 5   finance   12960 non-null  object\n",
      " 6   social    12960 non-null  object\n",
      " 7   health    12960 non-null  object\n",
      " 8   class     12960 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 911.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*missing value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parents     0\n",
       "has_nurs    0\n",
       "form        0\n",
       "children    0\n",
       "housing     0\n",
       "finance     0\n",
       "social      0\n",
       "health      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*duplicate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*outlier check*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parents\n",
      "parents\n",
      "usual          4320\n",
      "pretentious    4320\n",
      "great_pret     4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "has_nurs\n",
      "has_nurs\n",
      "proper         2592\n",
      "less_proper    2592\n",
      "improper       2592\n",
      "critical       2592\n",
      "very_crit      2592\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "form\n",
      "form\n",
      "complete      3240\n",
      "completed     3240\n",
      "incomplete    3240\n",
      "foster        3240\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "children\n",
      "children\n",
      "1       3240\n",
      "2       3240\n",
      "3       3240\n",
      "more    3240\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "housing\n",
      "housing\n",
      "convenient    4320\n",
      "less_conv     4320\n",
      "critical      4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "finance\n",
      "finance\n",
      "convenient    6480\n",
      "inconv        6480\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "social\n",
      "social\n",
      "nonprob          4320\n",
      "slightly_prob    4320\n",
      "problematic      4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "health\n",
      "health\n",
      "recommended    4320\n",
      "priority       4320\n",
      "not_recom      4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "class\n",
      "class\n",
      "not_recom     4320\n",
      "priority      4266\n",
      "spec_prior    4044\n",
      "very_recom     328\n",
      "recommend        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pemilihan kelas dan kolom*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "not_recom     4320\n",
      "priority      4266\n",
      "spec_prior    4044\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter hanya baris dengan class 'not_recom', 'priority' dan 'spec prior'\n",
    "df_pilihan = df[df['class'].isin(['not_recom', 'priority', 'spec_prior'])]\n",
    "\n",
    "# Tampilkan jumlah kelas 'not_recom' dan 'priority'\n",
    "print(df_pilihan['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      finance         social       health      class\n",
       "1  convenient        nonprob     priority   priority\n",
       "2  convenient        nonprob    not_recom  not_recom\n",
       "4  convenient  slightly_prob     priority   priority\n",
       "5  convenient  slightly_prob    not_recom  not_recom\n",
       "6  convenient    problematic  recommended   priority"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pilih kolom yang akan digunakan\n",
    "kolom_pilihan = ['finance', 'social', 'health', 'class']\n",
    "df_pilihan = df_pilihan[kolom_pilihan].copy()\n",
    "\n",
    "df_pilihan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   finance  social  health  class\n",
       "1        0       0       1      1\n",
       "2        0       0       0      0\n",
       "4        0       2       1      1\n",
       "5        0       2       0      0\n",
       "6        0       1       2      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df_pilihan['social'] = le.fit_transform(df_pilihan['social']).astype(int)\n",
    "df_pilihan['finance'] = le.fit_transform(df_pilihan['finance']).astype(int)\n",
    "df_pilihan['health'] = le.fit_transform(df_pilihan['health']).astype(int)\n",
    "df_pilihan['class'] = le.fit_transform(df_pilihan['class']).astype(int)\n",
    "\n",
    "df_pilihan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*splitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Training:  (10104, 3)\n",
      "Data Testing:  (2526, 3)\n"
     ]
    }
   ],
   "source": [
    "X = df_pilihan[['social', 'finance', 'health']]\n",
    "y = df_pilihan['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data Training: \", X_train.shape)\n",
    "print(\"Data Testing: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Modeling Evaluasi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', decision_function_shape='ovo')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predict = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil = X_test.copy()\n",
    "df_hasil['Label asli'] = y_test.values\n",
    "df_hasil['Label prediksi'] = svm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       social  finance  health  Label asli  Label prediksi  Prediksi benar\n",
      "9234        0        0       2           1               1            True\n",
      "11965       2        1       1           2               2            True\n",
      "4530        2        1       2           1               1            True\n",
      "11732       2        1       0           0               0            True\n",
      "8441        1        1       0           0               0            True\n",
      "11107       0        0       1           2               2            True\n",
      "7272        0        0       2           2               1           False\n",
      "12532       2        0       1           2               2            True\n",
      "1057        2        1       1           1               2           False\n",
      "1707        1        1       2           1               1            True\n",
      "1817        1        1       0           0               0            True\n",
      "8152        1        1       1           2               2            True\n",
      "10081       0        0       1           2               2            True\n",
      "11493       0        1       2           2               1           False\n",
      "10460       0        0       0           0               0            True\n",
      "12347       1        1       0           0               0            True\n",
      "8591        2        0       0           0               0            True\n",
      "2464        1        1       1           1               2           False\n",
      "5532        1        0       2           1               1            True\n",
      "3324        2        1       2           1               1            True\n",
      "Jumlah hasil prediksi yang benar adalah 1836\n"
     ]
    }
   ],
   "source": [
    "df_hasil['Prediksi benar'] = df_hasil['Label asli'] == df_hasil['Label prediksi']\n",
    "prediksi_benar = df_hasil['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasil.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasil.to_csv('Hasil_prediksiSVM_Linear.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7268408551068883\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       896\n",
      "           1       0.61      0.55      0.58       861\n",
      "           2       0.55      0.60      0.57       769\n",
      "\n",
      "    accuracy                           0.73      2526\n",
      "   macro avg       0.72      0.72      0.72      2526\n",
      "weighted avg       0.73      0.73      0.73      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[896   0   0]\n",
      " [  0 476 385]\n",
      " [  0 305 464]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, svm_predict)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test, svm_predict)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, svm_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.68923199 0.70190024 0.72961203 0.7442597  0.77632621]\n",
      "Rata Rata Accuracy: 0.73\n",
      "Standar Deviasi: 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "sk_fold = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(svm_model, X, y, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_modelrbf = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "svm_modelrbf.fit(X_train, y_train)\n",
    "svm_predrbf = svm_modelrbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasilrbf = X_test.copy()\n",
    "df_hasilrbf['Label asli'] = y_test.values\n",
    "df_hasilrbf['Label prediksi'] = svm_predrbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       social  finance  health  Label asli  Label prediksi  Prediksi benar\n",
      "9234        0        0       2           1               1            True\n",
      "11965       2        1       1           2               2            True\n",
      "4530        2        1       2           1               1            True\n",
      "11732       2        1       0           0               0            True\n",
      "8441        1        1       0           0               0            True\n",
      "11107       0        0       1           2               2            True\n",
      "7272        0        0       2           2               1           False\n",
      "12532       2        0       1           2               2            True\n",
      "1057        2        1       1           1               2           False\n",
      "1707        1        1       2           1               2           False\n",
      "1817        1        1       0           0               0            True\n",
      "8152        1        1       1           2               2            True\n",
      "10081       0        0       1           2               2            True\n",
      "11493       0        1       2           2               1           False\n",
      "10460       0        0       0           0               0            True\n",
      "12347       1        1       0           0               0            True\n",
      "8591        2        0       0           0               0            True\n",
      "2464        1        1       1           1               2           False\n",
      "5532        1        0       2           1               2           False\n",
      "3324        2        1       2           1               1            True\n",
      "Jumlah hasil prediksi yang benar adalah 1866\n"
     ]
    }
   ],
   "source": [
    "df_hasilrbf['Prediksi benar'] = df_hasilrbf['Label asli'] == df_hasilrbf['Label prediksi']\n",
    "prediksi_benarrbf = df_hasilrbf['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasilrbf.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benarrbf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasilrbf.to_csv('Hasil_prediksiSVM_rbf.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7387173396674585\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       896\n",
      "           1       0.70      0.41      0.51       861\n",
      "           2       0.55      0.81      0.65       769\n",
      "\n",
      "    accuracy                           0.74      2526\n",
      "   macro avg       0.75      0.74      0.72      2526\n",
      "weighted avg       0.76      0.74      0.73      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[896   0   0]\n",
      " [  0 349 512]\n",
      " [  0 148 621]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score: {accuracy_score(y_test, svm_predrbf)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test, svm_predrbf)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, svm_predrbf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.69200317 0.70942201 0.746635   0.76524149 0.8087886 ]\n",
      "Rata Rata Accuracy: 0.74\n",
      "Standar Deviasi: 0.04\n"
     ]
    }
   ],
   "source": [
    "sk_fold = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(svm_modelrbf, X, y, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Menyimpan model ke pickle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump(svm_model, open('linear_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_linear = pickle.load(open('linear_model', 'rb'))\n",
    "# result_linear = loaded_model_linear.score(X_test, y_test)\n",
    "# print(result_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(svm_modelrbf, open('rbf_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_rbf = pickle.load(open('rbf_model', 'rb'))\n",
    "# result_rbf = loaded_model_rbf.score(X_test, y_test)\n",
    "# print(result_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualisasi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Kurangi dimensi untuk visualisasi (2D) dengan PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "# X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# # Visualisasi SVM pada data training\n",
    "# def plot_pca_decision_boundary(X, y, model):\n",
    "#     x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "#     y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 \n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "#     # Prediksi model pada tiap titik meshgrid\n",
    "#     Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     # Hasil plot area keputusan\n",
    "#     plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
    "\n",
    "#     # Plot data training\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "#     plt.xlabel('Komponen PCA 1') # namanya ganti\n",
    "#     plt.ylabel('Komponen PCA 2')\n",
    "#     plt.title('Visualisasi Batas SVM Dataset Nursery')\n",
    "#     plt.show()\n",
    "\n",
    "# # Panggil fungsi untuk memvisualisasikan dengan model SVM terlatih\n",
    "# plot_pca_decision_boundary(X_train_pca, y_train,svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Kurangi dimensi untuk visualisasi (2D) dengan PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "# X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# # Melatih model SVM dengan kernel RBF\n",
    "# svm_model_rbf = SVC(kernel='rbf', gamma='auto')\n",
    "# svm_model_rbf.fit(X_train, y_train)\n",
    "\n",
    "# # Visualisasi SVM dengan boundary keputusan\n",
    "# def plot_pca_decision_boundary(X, y, model):\n",
    "#     x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "#     y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 \n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "#     # Prediksi model pada tiap titik meshgrid\n",
    "#     Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     # Plot area keputusan\n",
    "#     plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
    "\n",
    "#     # Plot data latih\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "#     plt.xlabel('Komponen PCA 1')\n",
    "#     plt.ylabel('Komponen PCA 2')\n",
    "#     plt.title('Visualisasi Batas Keputusan SVM dengan Kernel RBF')\n",
    "#     plt.show()\n",
    "\n",
    "# # Memanggil fungsi untuk memvisualisasikan dengan model SVM terlatih\n",
    "# plot_pca_decision_boundary(X_train_pca, y_train,svm_modelrbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_ann = y_train.copy()\n",
    "y_train_ann = to_categorical(y_train_ann, num_classes=3)\n",
    "y_test_ann = y_test.copy()\n",
    "y_test_ann = to_categorical(y_test_ann, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi data :\n",
      "\n",
      "X train \t X test \t Y train \t Y test\n",
      "(10104, 3) \t (2526, 3) \t (10104, 3) \t (2526, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensi data :\\n\")\n",
    "print(\"X train \\t X test \\t Y train \\t Y test\")  \n",
    "print(\"%s \\t %s \\t %s \\t %s\" % (X_train.shape, X_test.shape, y_train_ann.shape, y_test_ann.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelANN = Sequential()\n",
    "modelANN.add(Dense(6, activation='relu', input_dim=X_train.shape[1]))\n",
    "modelANN.add(Dense(3, activation='relu'))\n",
    "modelANN.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelANN.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5225 - loss: 1.0233 - val_accuracy: 0.5839 - val_loss: 0.8551\n",
      "Epoch 2/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 0.7786 - val_accuracy: 0.6447 - val_loss: 0.6548\n",
      "Epoch 3/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6646 - loss: 0.6166 - val_accuracy: 0.6447 - val_loss: 0.5849\n",
      "Epoch 4/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.5498 - val_accuracy: 0.6447 - val_loss: 0.5512\n",
      "Epoch 5/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6774 - loss: 0.5286 - val_accuracy: 0.6823 - val_loss: 0.5310\n",
      "Epoch 6/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6535 - loss: 0.5197 - val_accuracy: 0.6823 - val_loss: 0.5175\n",
      "Epoch 7/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6810 - loss: 0.5023 - val_accuracy: 0.6823 - val_loss: 0.5080\n",
      "Epoch 8/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6723 - loss: 0.5043 - val_accuracy: 0.6823 - val_loss: 0.5009\n",
      "Epoch 9/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6649 - loss: 0.4957 - val_accuracy: 0.6823 - val_loss: 0.4954\n",
      "Epoch 10/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.4896 - val_accuracy: 0.6823 - val_loss: 0.4911\n",
      "Epoch 11/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 0.4786 - val_accuracy: 0.6823 - val_loss: 0.4878\n",
      "Epoch 12/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6822 - loss: 0.4738 - val_accuracy: 0.6823 - val_loss: 0.4850\n",
      "Epoch 13/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6745 - loss: 0.4725 - val_accuracy: 0.6823 - val_loss: 0.4825\n",
      "Epoch 14/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.4743 - val_accuracy: 0.6823 - val_loss: 0.4804\n",
      "Epoch 15/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6736 - loss: 0.4709 - val_accuracy: 0.6823 - val_loss: 0.4788\n",
      "Epoch 16/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6725 - loss: 0.4645 - val_accuracy: 0.6823 - val_loss: 0.4772\n",
      "Epoch 17/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 0.4656 - val_accuracy: 0.6823 - val_loss: 0.4761\n",
      "Epoch 18/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.4654 - val_accuracy: 0.6823 - val_loss: 0.4748\n",
      "Epoch 19/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6788 - loss: 0.4615 - val_accuracy: 0.6823 - val_loss: 0.4742\n",
      "Epoch 20/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6719 - loss: 0.4652 - val_accuracy: 0.6823 - val_loss: 0.4732\n",
      "Epoch 21/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.4618 - val_accuracy: 0.6823 - val_loss: 0.4725\n",
      "Epoch 22/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6794 - loss: 0.4593 - val_accuracy: 0.6823 - val_loss: 0.4718\n",
      "Epoch 23/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6653 - loss: 0.4674 - val_accuracy: 0.6937 - val_loss: 0.4713\n",
      "Epoch 24/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7126 - loss: 0.4609 - val_accuracy: 0.7199 - val_loss: 0.4674\n",
      "Epoch 25/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7187 - loss: 0.4621 - val_accuracy: 0.7199 - val_loss: 0.4640\n",
      "Epoch 26/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.4532 - val_accuracy: 0.7185 - val_loss: 0.4625\n",
      "Epoch 27/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.4548 - val_accuracy: 0.7239 - val_loss: 0.4623\n",
      "Epoch 28/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7253 - loss: 0.4547 - val_accuracy: 0.7239 - val_loss: 0.4603\n",
      "Epoch 29/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.4586 - val_accuracy: 0.7239 - val_loss: 0.4604\n",
      "Epoch 30/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.4442 - val_accuracy: 0.7239 - val_loss: 0.4581\n",
      "Epoch 31/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7236 - loss: 0.4517 - val_accuracy: 0.7239 - val_loss: 0.4570\n",
      "Epoch 32/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7175 - loss: 0.4483 - val_accuracy: 0.7264 - val_loss: 0.4575\n",
      "Epoch 33/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.4530 - val_accuracy: 0.7239 - val_loss: 0.4560\n",
      "Epoch 34/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.4438 - val_accuracy: 0.7264 - val_loss: 0.4559\n",
      "Epoch 35/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.4466 - val_accuracy: 0.7239 - val_loss: 0.4549\n",
      "Epoch 36/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.4468 - val_accuracy: 0.7264 - val_loss: 0.4545\n",
      "Epoch 37/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.4514 - val_accuracy: 0.7264 - val_loss: 0.4542\n",
      "Epoch 38/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.4385 - val_accuracy: 0.7264 - val_loss: 0.4544\n",
      "Epoch 39/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7260 - loss: 0.4522 - val_accuracy: 0.7264 - val_loss: 0.4544\n",
      "Epoch 40/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.4429 - val_accuracy: 0.7264 - val_loss: 0.4538\n",
      "Epoch 41/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.4556 - val_accuracy: 0.7264 - val_loss: 0.4537\n",
      "Epoch 42/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7263 - loss: 0.4481 - val_accuracy: 0.7264 - val_loss: 0.4552\n",
      "Epoch 43/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7277 - loss: 0.4504 - val_accuracy: 0.7264 - val_loss: 0.4546\n",
      "Epoch 44/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.4443 - val_accuracy: 0.7264 - val_loss: 0.4537\n",
      "Epoch 45/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.4445 - val_accuracy: 0.7264 - val_loss: 0.4534\n",
      "Epoch 46/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.4385 - val_accuracy: 0.7264 - val_loss: 0.4535\n",
      "Epoch 47/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.4490 - val_accuracy: 0.7264 - val_loss: 0.4536\n",
      "Epoch 48/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7201 - loss: 0.4496 - val_accuracy: 0.7264 - val_loss: 0.4543\n",
      "Epoch 49/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.4462 - val_accuracy: 0.7264 - val_loss: 0.4532\n",
      "Epoch 50/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: 0.4503 - val_accuracy: 0.7264 - val_loss: 0.4534\n"
     ]
    }
   ],
   "source": [
    "history = modelANN.fit(X_train, y_train_ann, \n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7241 - loss: 0.4381\n",
      "Test Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelANN.evaluate(X_test, y_test_ann)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ann_predict = modelANN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predict_classes = np.argmax(ann_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [1 2 1 0 0 2 1 2 2 1 0 2 2 1 0 0 0 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions: \", y_predict_classes[:20])  # Tampilkan 10 prediksi pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = np.argmax(y_test_ann, axis=1)\n",
    "y_pred_labels = np.argmax(ann_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasilnn = X_test.copy()\n",
    "df_hasilnn['Label asli'] = y_test_labels\n",
    "df_hasilnn['Label prediksi'] = y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       social  finance  health  Label asli  Label prediksi  Prediksi benar\n",
      "9234        0        0       2           1               1            True\n",
      "11965       2        1       1           2               2            True\n",
      "4530        2        1       2           1               1            True\n",
      "11732       2        1       0           0               0            True\n",
      "8441        1        1       0           0               0            True\n",
      "11107       0        0       1           2               2            True\n",
      "7272        0        0       2           2               1           False\n",
      "12532       2        0       1           2               2            True\n",
      "1057        2        1       1           1               2           False\n",
      "1707        1        1       2           1               1            True\n",
      "1817        1        1       0           0               0            True\n",
      "8152        1        1       1           2               2            True\n",
      "10081       0        0       1           2               2            True\n",
      "11493       0        1       2           2               1           False\n",
      "10460       0        0       0           0               0            True\n",
      "12347       1        1       0           0               0            True\n",
      "8591        2        0       0           0               0            True\n",
      "2464        1        1       1           1               2           False\n",
      "5532        1        0       2           1               1            True\n",
      "3324        2        1       2           1               1            True\n",
      "Jumlah hasil prediksi yang benar adalah 1836\n"
     ]
    }
   ],
   "source": [
    "df_hasilnn['Prediksi benar'] = df_hasilnn['Label asli'] == df_hasilnn['Label prediksi']\n",
    "prediksi_benarnn = df_hasilnn['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasilnn.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benarnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7268408551068883\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       896\n",
      "           1       0.61      0.55      0.58       861\n",
      "           2       0.55      0.60      0.57       769\n",
      "\n",
      "    accuracy                           0.73      2526\n",
      "   macro avg       0.72      0.72      0.72      2526\n",
      "weighted avg       0.73      0.73      0.73      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[896   0   0]\n",
      " [  0 476 385]\n",
      " [  0 305 464]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score: {accuracy_score(y_test_labels, y_pred_labels)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test_labels, y_pred_labels)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test_labels, y_pred_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parents  has_nurs  form  children  housing  finance  social  health  class\n",
       "0        2         3     0         0        0        0       0       2      2\n",
       "1        2         3     0         0        0        0       0       1      1\n",
       "2        2         3     0         0        0        0       0       0      0\n",
       "3        2         3     0         0        0        0       2       2      2\n",
       "4        2         3     0         0        0        0       2       1      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode semua kolom\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*data splitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Training:  (10368, 8)\n",
      "Data Testing:  (2592, 8)\n"
     ]
    }
   ],
   "source": [
    "X2 = df.drop(columns=['class'])  # Semua fitur kecuali 'class'\n",
    "y2 = df['class']                 # Target\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data Training: \", X_train2.shape)\n",
    "print(\"Data Testing: \", X_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*menentukan atribut pca*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.98497442,  0.71286742, -0.1479329 ,  0.23596993, -0.40607873,\n",
       "         0.74420362],\n",
       "       [ 2.02994841,  0.49045403,  2.05978838, -0.35596421, -0.80343002,\n",
       "        -1.44208082],\n",
       "       [-1.97577936,  1.04894903,  1.21363214,  0.91990725,  0.76928533,\n",
       "        -0.1276976 ],\n",
       "       ...,\n",
       "       [-0.00725245, -2.05869464,  0.51942085, -0.53214721, -0.38625242,\n",
       "        -0.62119099],\n",
       "       [ 1.01648895, -0.35139351,  1.55037133, -0.28039433, -0.76323714,\n",
       "         0.12321463],\n",
       "       [-2.0035363 , -0.66447437,  0.19081325, -0.41223272,  0.82697987,\n",
       "         0.09231828]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.85)\n",
    "Xtrain_pca = pca.fit_transform(X_train2)\n",
    "Xtrain_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komponen PCA:\n",
      "[[-1.25718073e-03  9.99897781e-01  1.25525987e-02  2.96572896e-03\n",
      "  -2.40280869e-03 -3.91688915e-03  3.91249057e-03  2.44537557e-04]\n",
      " [ 2.21585840e-03 -9.18134006e-03  8.54527864e-01 -5.19246423e-01\n",
      "  -6.28324991e-03  5.07124132e-03  1.39635763e-04  3.29530429e-03]\n",
      " [-4.40129123e-05 -9.03556312e-03  5.19173591e-01  8.54504377e-01\n",
      "  -1.97623026e-05  2.53699465e-03 -8.54116394e-04 -1.38651731e-02]\n",
      " [ 6.18842968e-01  1.11388862e-03 -1.18795885e-03  9.22394965e-03\n",
      "  -4.22222560e-01  8.31146001e-03 -3.74139514e-01  5.46465280e-01]\n",
      " [ 8.48987463e-04  3.40603544e-03  6.04562430e-03  2.05762678e-03\n",
      "   8.37927230e-01  3.31868171e-03 -3.96649672e-01  3.74810455e-01]\n",
      " [-3.12073689e-02 -3.08388408e-03  3.48332682e-03  8.82976970e-03\n",
      "   8.41964853e-02 -4.52705656e-04  7.72182926e-01  6.28944169e-01]]\n",
      "Komponen 1:\n",
      "          Komponen 1\n",
      "parents    -0.001257\n",
      "has_nurs    0.999898\n",
      "form        0.012553\n",
      "children    0.002966\n",
      "housing    -0.002403\n",
      "finance    -0.003917\n",
      "social      0.003912\n",
      "health      0.000245\n",
      "Komponen 2:\n",
      "          Komponen 2\n",
      "parents     0.002216\n",
      "has_nurs   -0.009181\n",
      "form        0.854528\n",
      "children   -0.519246\n",
      "housing    -0.006283\n",
      "finance     0.005071\n",
      "social      0.000140\n",
      "health      0.003295\n",
      "Komponen 3:\n",
      "          Komponen 3\n",
      "parents    -0.000044\n",
      "has_nurs   -0.009036\n",
      "form        0.519174\n",
      "children    0.854504\n",
      "housing    -0.000020\n",
      "finance     0.002537\n",
      "social     -0.000854\n",
      "health     -0.013865\n",
      "Komponen 4:\n",
      "          Komponen 4\n",
      "parents     0.618843\n",
      "has_nurs    0.001114\n",
      "form       -0.001188\n",
      "children    0.009224\n",
      "housing    -0.422223\n",
      "finance     0.008311\n",
      "social     -0.374140\n",
      "health      0.546465\n",
      "Komponen 5:\n",
      "          Komponen 5\n",
      "parents     0.000849\n",
      "has_nurs    0.003406\n",
      "form        0.006046\n",
      "children    0.002058\n",
      "housing     0.837927\n",
      "finance     0.003319\n",
      "social     -0.396650\n",
      "health      0.374810\n",
      "Komponen 6:\n",
      "          Komponen 6\n",
      "parents    -0.031207\n",
      "has_nurs   -0.003084\n",
      "form        0.003483\n",
      "children    0.008830\n",
      "housing     0.084196\n",
      "finance    -0.000453\n",
      "social      0.772183\n",
      "health      0.628944\n"
     ]
    }
   ],
   "source": [
    "# Melihat komponen utama yang dihasilkan oleh PCA\n",
    "print(\"Komponen PCA:\")\n",
    "print(pca.components_)\n",
    "\n",
    "# Jika Anda ingin melihat kontribusi masing-masing fitur pada komponen utama\n",
    "# Kita anggap X_train2 memiliki nama kolom yang representatif\n",
    "feature_names = X_train2.columns  # Nama fitur asli\n",
    "\n",
    "# Menampilkan bobot komponen untuk setiap fitur\n",
    "for i, component in enumerate(pca.components_):\n",
    "    print(f\"Komponen {i + 1}:\")\n",
    "    component_df = pd.DataFrame(component, index=feature_names, columns=[f\"Komponen {i + 1}\"])\n",
    "    print(component_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_pca = pca.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling SVM dengan PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*svm linear*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pcalin_model = SVC(kernel='linear', decision_function_shape='ovo')\n",
    "pcalin_model.fit(Xtrain_pca, y_train2)\n",
    "pcalin_predict = pcalin_model.predict(Xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil_pcalin = pd.DataFrame(Xtest_pca, columns=[f'PC{i+1}' for i in range(Xtest_pca.shape[1])])\n",
    "df_hasil_pcalin['Label asli'] = y_test2.values\n",
    "df_hasil_pcalin['Label prediksi'] = pcalin_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1       PC2       PC3       PC4       PC5       PC6  Label asli  \\\n",
      "0  -1.003883 -0.676951  0.195643 -0.957584  0.455575 -0.539710           0   \n",
      "1  -1.007163  0.365910 -1.528894  0.358484  0.381674 -0.784352           3   \n",
      "2   0.991934 -0.170556 -0.690842  0.200728  0.835989  0.043029           1   \n",
      "3   1.998768 -1.216518  1.010093 -0.221034  0.400535 -0.736360           3   \n",
      "4  -0.988287  1.219637 -0.997608 -0.318605 -0.779541  0.103346           0   \n",
      "5  -1.003010  0.374555 -1.541931  0.164982 -0.033496  1.388505           1   \n",
      "6   2.017391  2.044126 -0.503789 -0.187016  0.029173 -1.415581           0   \n",
      "7  -2.019174 -0.981818 -1.195880  1.963624 -0.084669 -0.262834           1   \n",
      "8  -1.002749 -2.042783  0.499872  0.185530 -0.036687  1.411964           1   \n",
      "9  -0.014395 -0.503804 -2.058831 -0.809716  0.423663  0.837643           1   \n",
      "10  0.027121  1.552960  0.354087  0.414529 -0.835348 -0.083653           1   \n",
      "11  1.020956  1.533428  0.344968  0.190041  0.844762  0.050449           1   \n",
      "12  0.984894 -0.501638 -2.053152  0.482360 -1.226098 -0.766168           0   \n",
      "13  0.992645 -2.067876  0.510385 -0.531033 -0.382846 -0.624275           0   \n",
      "14  2.007731  1.202472 -1.050673  1.329325 -0.065179 -0.245372           1   \n",
      "15 -1.995909  0.195425  0.696932  1.126027  1.605335 -0.078645           1   \n",
      "16 -0.012182 -2.048112  0.508049  0.641472 -0.007274 -0.023907           1   \n",
      "17 -0.987289  0.193739  0.685399  1.963275 -0.070432 -0.249669           4   \n",
      "18 -0.994920 -0.660950  0.180963  0.059187 -1.242118  0.693024           3   \n",
      "19  0.003191  0.688582 -0.161691 -0.665120  1.233581 -0.660171           3   \n",
      "\n",
      "    Label prediksi  Prediksi benar  \n",
      "0                0            True  \n",
      "1                1           False  \n",
      "2                1            True  \n",
      "3                0           False  \n",
      "4                3           False  \n",
      "5                1            True  \n",
      "6                0            True  \n",
      "7                1            True  \n",
      "8                1            True  \n",
      "9                3           False  \n",
      "10               3           False  \n",
      "11               3           False  \n",
      "12               0            True  \n",
      "13               0            True  \n",
      "14               1            True  \n",
      "15               1            True  \n",
      "16               1            True  \n",
      "17               1           False  \n",
      "18               3            True  \n",
      "19               3            True  \n",
      "Jumlah hasil prediksi yang benar adalah 1809\n"
     ]
    }
   ],
   "source": [
    "df_hasil_pcalin['Prediksi benar'] = df_hasil_pcalin['Label asli'] == df_hasil_pcalin['Label prediksi']\n",
    "prediksi_benar_pcalin = df_hasil_pcalin['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasil_pcalin.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benar_pcalin}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasil_pcalin.to_csv('Hasil_prediksiSVM_Linear_pca.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6979166666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       870\n",
      "           1       0.64      0.70      0.67       873\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.56      0.55      0.55       785\n",
      "           4       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.70      2592\n",
      "   macro avg       0.42      0.43      0.42      2592\n",
      "weighted avg       0.68      0.70      0.69      2592\n",
      "\n",
      "Confusion Matrix:\n",
      " [[772   0   0  98   0]\n",
      " [ 22 607   0 244   0]\n",
      " [  0   2   0   0   0]\n",
      " [ 81 274   0 430   0]\n",
      " [  0  62   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test2, pcalin_predict)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test2, pcalin_predict)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test2, pcalin_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.67052469 0.76080247 0.77121914 0.84104938 0.64544753]\n",
      "Rata Rata Accuracy: 0.74\n",
      "Standar Deviasi: 0.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "sk_fold = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(pcalin_model, X2, y2, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*svm rbf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pcarbf_model = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "pcarbf_model.fit(Xtrain_pca, y_train2)\n",
    "pcarbf_predict = pcarbf_model.predict(Xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil_pcarbf = pd.DataFrame(Xtest_pca, columns=[f'PC{i+1}' for i in range(Xtest_pca.shape[1])])\n",
    "df_hasil_pcarbf['Label asli'] = y_test2.values\n",
    "df_hasil_pcarbf['Label prediksi'] = pcarbf_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1       PC2       PC3       PC4       PC5       PC6  Label asli  \\\n",
      "0  -1.003883 -0.676951  0.195643 -0.957584  0.455575 -0.539710           0   \n",
      "1  -1.007163  0.365910 -1.528894  0.358484  0.381674 -0.784352           3   \n",
      "2   0.991934 -0.170556 -0.690842  0.200728  0.835989  0.043029           1   \n",
      "3   1.998768 -1.216518  1.010093 -0.221034  0.400535 -0.736360           3   \n",
      "4  -0.988287  1.219637 -0.997608 -0.318605 -0.779541  0.103346           0   \n",
      "5  -1.003010  0.374555 -1.541931  0.164982 -0.033496  1.388505           1   \n",
      "6   2.017391  2.044126 -0.503789 -0.187016  0.029173 -1.415581           0   \n",
      "7  -2.019174 -0.981818 -1.195880  1.963624 -0.084669 -0.262834           1   \n",
      "8  -1.002749 -2.042783  0.499872  0.185530 -0.036687  1.411964           1   \n",
      "9  -0.014395 -0.503804 -2.058831 -0.809716  0.423663  0.837643           1   \n",
      "10  0.027121  1.552960  0.354087  0.414529 -0.835348 -0.083653           1   \n",
      "11  1.020956  1.533428  0.344968  0.190041  0.844762  0.050449           1   \n",
      "12  0.984894 -0.501638 -2.053152  0.482360 -1.226098 -0.766168           0   \n",
      "13  0.992645 -2.067876  0.510385 -0.531033 -0.382846 -0.624275           0   \n",
      "14  2.007731  1.202472 -1.050673  1.329325 -0.065179 -0.245372           1   \n",
      "15 -1.995909  0.195425  0.696932  1.126027  1.605335 -0.078645           1   \n",
      "16 -0.012182 -2.048112  0.508049  0.641472 -0.007274 -0.023907           1   \n",
      "17 -0.987289  0.193739  0.685399  1.963275 -0.070432 -0.249669           4   \n",
      "18 -0.994920 -0.660950  0.180963  0.059187 -1.242118  0.693024           3   \n",
      "19  0.003191  0.688582 -0.161691 -0.665120  1.233581 -0.660171           3   \n",
      "\n",
      "    Label prediksi  Prediksi benar  \n",
      "0                0            True  \n",
      "1                1           False  \n",
      "2                1            True  \n",
      "3                0           False  \n",
      "4                0            True  \n",
      "5                1            True  \n",
      "6                0            True  \n",
      "7                1            True  \n",
      "8                1            True  \n",
      "9                1            True  \n",
      "10               1            True  \n",
      "11               1            True  \n",
      "12               0            True  \n",
      "13               0            True  \n",
      "14               3           False  \n",
      "15               1            True  \n",
      "16               1            True  \n",
      "17               1           False  \n",
      "18               1           False  \n",
      "19               3            True  \n",
      "Jumlah hasil prediksi yang benar adalah 2172\n"
     ]
    }
   ],
   "source": [
    "df_hasil_pcarbf['Prediksi benar'] = df_hasil_pcarbf['Label asli'] == df_hasil_pcarbf['Label prediksi']\n",
    "prediksi_benar_pcarbf = df_hasil_pcarbf['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasil_pcarbf.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benar_pcarbf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasil_pcarbf.to_csv('Hasil_prediksiSVM_rbf_pca.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8379629629629629\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       870\n",
      "           1       0.85      0.84      0.85       873\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.79      0.79      0.79       785\n",
      "           4       0.80      0.06      0.12        62\n",
      "\n",
      "    accuracy                           0.84      2592\n",
      "   macro avg       0.66      0.53      0.53      2592\n",
      "weighted avg       0.84      0.84      0.83      2592\n",
      "\n",
      "Confusion Matrix:\n",
      " [[813   0   0  57   0]\n",
      " [ 25 736   0 112   0]\n",
      " [  0   1   0   0   1]\n",
      " [ 98  68   0 619   0]\n",
      " [  0  58   0   0   4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test2, pcarbf_predict)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test2, pcarbf_predict)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test2, pcarbf_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.75270062 0.88503086 0.83912037 0.88001543 0.68325617]\n",
      "Rata Rata Accuracy: 0.81\n",
      "Standar Deviasi: 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "sk_fold = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(pcarbf_model, X2, y2, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling NN dengan PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Xtrain_pca = np.array(Xtrain_pca)\n",
    "y_train2_ann = np.array(y_train2_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train2_ann = y_train2.copy()\n",
    "y_train2_ann = to_categorical(y_train2_ann, num_classes=5)\n",
    "y_test2_ann = y_test2.copy()\n",
    "y_test2_ann = to_categorical(y_test2_ann, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi data :\n",
      "\n",
      "X train \t X test \t Y train \t Y test\n",
      "(10368, 6) \t (2592, 6) \t (10368, 5) \t (2592, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensi data :\\n\")\n",
    "print(\"X train \\t X test \\t Y train \\t Y test\")  \n",
    "print(\"%s \\t %s \\t %s \\t %s\" % (Xtrain_pca.shape, Xtest_pca.shape, y_train2_ann.shape, y_test2_ann.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelANN2 = Sequential()\n",
    "modelANN2.add(Dense(32, activation='relu', input_dim=Xtrain_pca.shape[1]))\n",
    "modelANN2.add(Dense(16, activation='relu'))\n",
    "modelANN2.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelANN2.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m85\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">837</span> (3.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m837\u001b[0m (3.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">837</span> (3.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m837\u001b[0m (3.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelANN2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4878 - loss: 1.1913 - val_accuracy: 0.7170 - val_loss: 0.6614\n",
      "Epoch 2/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7353 - loss: 0.6222 - val_accuracy: 0.7830 - val_loss: 0.5100\n",
      "Epoch 3/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8030 - loss: 0.4842 - val_accuracy: 0.8197 - val_loss: 0.4353\n",
      "Epoch 4/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8247 - loss: 0.4294 - val_accuracy: 0.8235 - val_loss: 0.4102\n",
      "Epoch 5/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8362 - loss: 0.3964 - val_accuracy: 0.8284 - val_loss: 0.3994\n",
      "Epoch 6/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8294 - loss: 0.3991 - val_accuracy: 0.8177 - val_loss: 0.3942\n",
      "Epoch 7/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.3850 - val_accuracy: 0.8293 - val_loss: 0.3860\n",
      "Epoch 8/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8417 - loss: 0.3632 - val_accuracy: 0.8279 - val_loss: 0.3787\n",
      "Epoch 9/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8417 - loss: 0.3547 - val_accuracy: 0.8322 - val_loss: 0.3731\n",
      "Epoch 10/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8280 - loss: 0.3674 - val_accuracy: 0.8317 - val_loss: 0.3708\n",
      "Epoch 11/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8388 - loss: 0.3552 - val_accuracy: 0.8317 - val_loss: 0.3737\n",
      "Epoch 12/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8399 - loss: 0.3466 - val_accuracy: 0.8361 - val_loss: 0.3568\n",
      "Epoch 13/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8453 - loss: 0.3315 - val_accuracy: 0.8375 - val_loss: 0.3505\n",
      "Epoch 14/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8407 - loss: 0.3374 - val_accuracy: 0.8390 - val_loss: 0.3477\n",
      "Epoch 15/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.3377 - val_accuracy: 0.8390 - val_loss: 0.3455\n",
      "Epoch 16/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8472 - loss: 0.3305 - val_accuracy: 0.8375 - val_loss: 0.3398\n",
      "Epoch 17/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 0.3243 - val_accuracy: 0.8385 - val_loss: 0.3441\n",
      "Epoch 18/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8566 - loss: 0.3076 - val_accuracy: 0.8419 - val_loss: 0.3373\n",
      "Epoch 19/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8461 - loss: 0.3241 - val_accuracy: 0.8476 - val_loss: 0.3324\n",
      "Epoch 20/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8600 - loss: 0.2997 - val_accuracy: 0.8428 - val_loss: 0.3343\n",
      "Epoch 21/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8554 - loss: 0.3076 - val_accuracy: 0.8428 - val_loss: 0.3242\n",
      "Epoch 22/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 0.3022 - val_accuracy: 0.8467 - val_loss: 0.3266\n",
      "Epoch 23/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8518 - loss: 0.3045 - val_accuracy: 0.8486 - val_loss: 0.3234\n",
      "Epoch 24/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 0.3045 - val_accuracy: 0.8428 - val_loss: 0.3244\n",
      "Epoch 25/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8618 - loss: 0.2981 - val_accuracy: 0.8476 - val_loss: 0.3243\n",
      "Epoch 26/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 0.2996 - val_accuracy: 0.8423 - val_loss: 0.3209\n",
      "Epoch 27/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8573 - loss: 0.2933 - val_accuracy: 0.8457 - val_loss: 0.3182\n",
      "Epoch 28/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8621 - loss: 0.2832 - val_accuracy: 0.8443 - val_loss: 0.3176\n",
      "Epoch 29/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8523 - loss: 0.2974 - val_accuracy: 0.8491 - val_loss: 0.3105\n",
      "Epoch 30/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 0.2905 - val_accuracy: 0.8500 - val_loss: 0.3146\n",
      "Epoch 31/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.2779 - val_accuracy: 0.8476 - val_loss: 0.3038\n",
      "Epoch 32/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8675 - loss: 0.2787 - val_accuracy: 0.8481 - val_loss: 0.3087\n",
      "Epoch 33/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.2801 - val_accuracy: 0.8476 - val_loss: 0.3099\n",
      "Epoch 34/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.2790 - val_accuracy: 0.8447 - val_loss: 0.3061\n",
      "Epoch 35/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8697 - loss: 0.2683 - val_accuracy: 0.8457 - val_loss: 0.3047\n",
      "Epoch 36/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8659 - loss: 0.2706 - val_accuracy: 0.8544 - val_loss: 0.2996\n",
      "Epoch 37/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8636 - loss: 0.2737 - val_accuracy: 0.8457 - val_loss: 0.2939\n",
      "Epoch 38/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8649 - loss: 0.2611 - val_accuracy: 0.8500 - val_loss: 0.2955\n",
      "Epoch 39/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8706 - loss: 0.2595 - val_accuracy: 0.8510 - val_loss: 0.2895\n",
      "Epoch 40/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.2670 - val_accuracy: 0.8505 - val_loss: 0.2865\n",
      "Epoch 41/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8626 - loss: 0.2703 - val_accuracy: 0.8486 - val_loss: 0.2907\n",
      "Epoch 42/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8719 - loss: 0.2527 - val_accuracy: 0.8486 - val_loss: 0.2918\n",
      "Epoch 43/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.2516 - val_accuracy: 0.8573 - val_loss: 0.2820\n",
      "Epoch 44/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2512 - val_accuracy: 0.8568 - val_loss: 0.2750\n",
      "Epoch 45/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.2532 - val_accuracy: 0.8582 - val_loss: 0.2807\n",
      "Epoch 46/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.2416 - val_accuracy: 0.8597 - val_loss: 0.2742\n",
      "Epoch 47/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.2427 - val_accuracy: 0.8582 - val_loss: 0.2664\n",
      "Epoch 48/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.2440 - val_accuracy: 0.8650 - val_loss: 0.2653\n",
      "Epoch 49/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8823 - loss: 0.2396 - val_accuracy: 0.8795 - val_loss: 0.2627\n",
      "Epoch 50/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8862 - loss: 0.2306 - val_accuracy: 0.8766 - val_loss: 0.2566\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "# Early stopping callback \n",
    "earlyStop = EarlyStopping(monitor='val_loss', \n",
    "                          mode='min', \n",
    "                          patience=10, \n",
    "                          restore_best_weights=True) \n",
    "\n",
    "# Train the model with early stopping \n",
    "history2 = modelANN2.fit(Xtrain_pca, y_train2_ann, \n",
    "                         callbacks=[earlyStop], \n",
    "                         epochs=50, \n",
    "                         batch_size=32, \n",
    "                         shuffle=True, \n",
    "                         validation_split=0.2, \n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.2762\n",
      "Test Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelANN2.evaluate(Xtest_pca, y_test2_ann)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "ann2_predict = modelANN2.predict(Xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predict2_classes = np.argmax(ann2_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [0 3 1 3 0 1 0 1 1 1 1 1 0 0 3 1 1 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions: \", y_predict2_classes[:20])  # Tampilkan 10 prediksi pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2_labels = np.argmax(y_test2_ann, axis=1)\n",
    "y_pred2_labels = np.argmax(ann2_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_test2_labels = pd.Series(y_test2_labels)\n",
    "y_pred2_labels = pd.Series(y_pred2_labels)\n",
    "\n",
    "Xtest_pca = pd.DataFrame(Xtest_pca)\n",
    "df_hasilnn2 = Xtest_pca.copy()\n",
    "df_hasilnn2['Label asli'] = y_test2_labels\n",
    "df_hasilnn2['Label prediksi'] = y_pred2_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5  Label asli  \\\n",
      "0  -1.003883 -0.676951  0.195643 -0.957584  0.455575 -0.539710           0   \n",
      "1  -1.007163  0.365910 -1.528894  0.358484  0.381674 -0.784352           3   \n",
      "2   0.991934 -0.170556 -0.690842  0.200728  0.835989  0.043029           1   \n",
      "3   1.998768 -1.216518  1.010093 -0.221034  0.400535 -0.736360           3   \n",
      "4  -0.988287  1.219637 -0.997608 -0.318605 -0.779541  0.103346           0   \n",
      "5  -1.003010  0.374555 -1.541931  0.164982 -0.033496  1.388505           1   \n",
      "6   2.017391  2.044126 -0.503789 -0.187016  0.029173 -1.415581           0   \n",
      "7  -2.019174 -0.981818 -1.195880  1.963624 -0.084669 -0.262834           1   \n",
      "8  -1.002749 -2.042783  0.499872  0.185530 -0.036687  1.411964           1   \n",
      "9  -0.014395 -0.503804 -2.058831 -0.809716  0.423663  0.837643           1   \n",
      "10  0.027121  1.552960  0.354087  0.414529 -0.835348 -0.083653           1   \n",
      "11  1.020956  1.533428  0.344968  0.190041  0.844762  0.050449           1   \n",
      "12  0.984894 -0.501638 -2.053152  0.482360 -1.226098 -0.766168           0   \n",
      "13  0.992645 -2.067876  0.510385 -0.531033 -0.382846 -0.624275           0   \n",
      "14  2.007731  1.202472 -1.050673  1.329325 -0.065179 -0.245372           1   \n",
      "15 -1.995909  0.195425  0.696932  1.126027  1.605335 -0.078645           1   \n",
      "16 -0.012182 -2.048112  0.508049  0.641472 -0.007274 -0.023907           1   \n",
      "17 -0.987289  0.193739  0.685399  1.963275 -0.070432 -0.249669           4   \n",
      "18 -0.994920 -0.660950  0.180963  0.059187 -1.242118  0.693024           3   \n",
      "19  0.003191  0.688582 -0.161691 -0.665120  1.233581 -0.660171           3   \n",
      "\n",
      "    Label prediksi  Prediksi benar  \n",
      "0                0            True  \n",
      "1                3            True  \n",
      "2                1            True  \n",
      "3                3            True  \n",
      "4                0            True  \n",
      "5                1            True  \n",
      "6                0            True  \n",
      "7                1            True  \n",
      "8                1            True  \n",
      "9                1            True  \n",
      "10               1            True  \n",
      "11               1            True  \n",
      "12               0            True  \n",
      "13               0            True  \n",
      "14               3           False  \n",
      "15               1            True  \n",
      "16               1            True  \n",
      "17               1           False  \n",
      "18               1           False  \n",
      "19               3            True  \n",
      "Jumlah hasil prediksi yang benar adalah 2255\n"
     ]
    }
   ],
   "source": [
    "df_hasilnn2['Prediksi benar'] = df_hasilnn2['Label asli'] == df_hasilnn2['Label prediksi']\n",
    "prediksi_benarnn2 = df_hasilnn2['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasilnn2.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benarnn2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasilnn2.to_csv('Hasil_prediksiNN_pca.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8699845679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       870\n",
      "           1       0.87      0.88      0.87       873\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.83      0.84      0.83       785\n",
      "           4       0.63      0.50      0.56        62\n",
      "\n",
      "    accuracy                           0.87      2592\n",
      "   macro avg       0.65      0.63      0.64      2592\n",
      "weighted avg       0.87      0.87      0.87      2592\n",
      "\n",
      "Confusion Matrix:\n",
      " [[804   6   0  60   0]\n",
      " [ 16 764   0  77  16]\n",
      " [  0   0   0   0   2]\n",
      " [ 47  82   0 656   0]\n",
      " [  0  31   0   0  31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score: {accuracy_score(y_test2_labels, y_pred2_labels)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test2_labels, y_pred2_labels)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test2_labels, y_pred2_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model Terbaik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari keempat algoritma yang dicobakan, yaitu:\n",
    "1. SVM Tanpa PCA\n",
    "2. SVM dengan PCA\n",
    "3. Neural Network Tanpa PCA\n",
    "4. Neural Network dengan PCA\n",
    "\n",
    "Model yang menghasilkan akurasi terbaik adalah **Neural Network dengan PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the Keras model in HDF5 format\n",
    "modelANN2.save('modelANN2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
