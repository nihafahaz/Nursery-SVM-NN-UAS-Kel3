{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi Penerimaan Murid Prasekolah menggunakan Support Vector Machine (SVM) dan Neural Network (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KELOMPOK 3\n",
    "- 2210511046 Hanifah Az-Zahra\n",
    "- 2210511054 Dinda Cantika Putri\n",
    "- 2210511070 Choirunnisa Zalfaa Nabilah\n",
    "- 2210511072 Edwina Martha Putri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (69.0.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\edwin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas tensorflow scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parents has_nurs      form children     housing     finance         social  \\\n",
       "0   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "1   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "2   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "3   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "4   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "\n",
       "        health      class  \n",
       "0  recommended  recommend  \n",
       "1     priority   priority  \n",
       "2    not_recom  not_recom  \n",
       "3  recommended  recommend  \n",
       "4     priority   priority  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menambahkan header\n",
    "headers = [\"parents\", \"has_nurs\", \"form\", \"children\", \"housing\", \"finance\", \"social\", \"health\", \"class\"]\n",
    "df = pd.read_csv('nursery/nursery.data', names=headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4320</td>\n",
       "      <td>2592</td>\n",
       "      <td>3240</td>\n",
       "      <td>3240</td>\n",
       "      <td>4320</td>\n",
       "      <td>6480</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       parents has_nurs      form children     housing     finance   social  \\\n",
       "count    12960    12960     12960    12960       12960       12960    12960   \n",
       "unique       3        5         4        4           3           2        3   \n",
       "top      usual   proper  complete        1  convenient  convenient  nonprob   \n",
       "freq      4320     2592      3240     3240        4320        6480     4320   \n",
       "\n",
       "             health      class  \n",
       "count         12960      12960  \n",
       "unique            3          5  \n",
       "top     recommended  not_recom  \n",
       "freq           4320       4320  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12960 entries, 0 to 12959\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   parents   12960 non-null  object\n",
      " 1   has_nurs  12960 non-null  object\n",
      " 2   form      12960 non-null  object\n",
      " 3   children  12960 non-null  object\n",
      " 4   housing   12960 non-null  object\n",
      " 5   finance   12960 non-null  object\n",
      " 6   social    12960 non-null  object\n",
      " 7   health    12960 non-null  object\n",
      " 8   class     12960 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 911.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*missing value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parents     0\n",
       "has_nurs    0\n",
       "form        0\n",
       "children    0\n",
       "housing     0\n",
       "finance     0\n",
       "social      0\n",
       "health      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*duplicate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*outlier check*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parents\n",
      "parents\n",
      "usual          4320\n",
      "pretentious    4320\n",
      "great_pret     4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "has_nurs\n",
      "has_nurs\n",
      "proper         2592\n",
      "less_proper    2592\n",
      "improper       2592\n",
      "critical       2592\n",
      "very_crit      2592\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "form\n",
      "form\n",
      "complete      3240\n",
      "completed     3240\n",
      "incomplete    3240\n",
      "foster        3240\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "children\n",
      "children\n",
      "1       3240\n",
      "2       3240\n",
      "3       3240\n",
      "more    3240\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "housing\n",
      "housing\n",
      "convenient    4320\n",
      "less_conv     4320\n",
      "critical      4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "finance\n",
      "finance\n",
      "convenient    6480\n",
      "inconv        6480\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "social\n",
      "social\n",
      "nonprob          4320\n",
      "slightly_prob    4320\n",
      "problematic      4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "health\n",
      "health\n",
      "recommended    4320\n",
      "priority       4320\n",
      "not_recom      4320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "class\n",
      "class\n",
      "not_recom     4320\n",
      "priority      4266\n",
      "spec_prior    4044\n",
      "very_recom     328\n",
      "recommend        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pemilihan kelas dan kolom*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "not_recom     4320\n",
      "priority      4266\n",
      "spec_prior    4044\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter hanya baris dengan class 'not_recom', 'priority' dan 'spec prior'\n",
    "df = df[df['class'].isin(['not_recom', 'priority', 'spec_prior'])]\n",
    "\n",
    "# Tampilkan jumlah kelas 'not_recom' dan 'priority'\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      finance         social       health      class\n",
       "1  convenient        nonprob     priority   priority\n",
       "2  convenient        nonprob    not_recom  not_recom\n",
       "4  convenient  slightly_prob     priority   priority\n",
       "5  convenient  slightly_prob    not_recom  not_recom\n",
       "6  convenient    problematic  recommended   priority"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pilih kolom yang akan digunakan\n",
    "kolom_pilihan = ['finance', 'social', 'health', 'class']\n",
    "df_pilihan = df[kolom_pilihan].copy()\n",
    "\n",
    "df_pilihan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   finance  social  health  class\n",
       "1        0       0       1      1\n",
       "2        0       0       0      0\n",
       "4        0       2       1      1\n",
       "5        0       2       0      0\n",
       "6        0       1       2      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df_pilihan['social'] = le.fit_transform(df_pilihan['social']).astype(int)\n",
    "df_pilihan['finance'] = le.fit_transform(df_pilihan['finance']).astype(int)\n",
    "df_pilihan['health'] = le.fit_transform(df_pilihan['health']).astype(int)\n",
    "df_pilihan['class'] = le.fit_transform(df_pilihan['class']).astype(int)\n",
    "\n",
    "df_pilihan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*splitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Training:  (10104, 3)\n",
      "Data Testing:  (2526, 3)\n"
     ]
    }
   ],
   "source": [
    "X = df_pilihan[['social', 'finance', 'health']]\n",
    "y = df_pilihan['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data Training: \", X_train.shape)\n",
    "print(\"Data Testing: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Modeling Evaluasi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', decision_function_shape='ovo')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predict = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil = X_test.copy()\n",
    "df_hasil['Label asli'] = y_test.values\n",
    "df_hasil['Label prediksi'] = svm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       social  finance  health  Label asli  Label prediksi  Prediksi benar\n",
      "9234        0        0       2           1               1            True\n",
      "11965       2        1       1           2               2            True\n",
      "4530        2        1       2           1               1            True\n",
      "11732       2        1       0           0               0            True\n",
      "8441        1        1       0           0               0            True\n",
      "11107       0        0       1           2               2            True\n",
      "7272        0        0       2           2               1           False\n",
      "12532       2        0       1           2               2            True\n",
      "1057        2        1       1           1               2           False\n",
      "1707        1        1       2           1               1            True\n",
      "1817        1        1       0           0               0            True\n",
      "8152        1        1       1           2               2            True\n",
      "10081       0        0       1           2               2            True\n",
      "11493       0        1       2           2               1           False\n",
      "10460       0        0       0           0               0            True\n",
      "12347       1        1       0           0               0            True\n",
      "8591        2        0       0           0               0            True\n",
      "2464        1        1       1           1               2           False\n",
      "5532        1        0       2           1               1            True\n",
      "3324        2        1       2           1               1            True\n",
      "Jumlah hasil prediksi yang benar adalah 1836\n"
     ]
    }
   ],
   "source": [
    "df_hasil['Prediksi benar'] = df_hasil['Label asli'] == df_hasil['Label prediksi']\n",
    "prediksi_benar = df_hasil['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasil.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasil.to_csv('Hasil_prediksiSVM_Linear.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7268408551068883\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       896\n",
      "           1       0.61      0.55      0.58       861\n",
      "           2       0.55      0.60      0.57       769\n",
      "\n",
      "    accuracy                           0.73      2526\n",
      "   macro avg       0.72      0.72      0.72      2526\n",
      "weighted avg       0.73      0.73      0.73      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[896   0   0]\n",
      " [  0 476 385]\n",
      " [  0 305 464]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, svm_predict)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test, svm_predict)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, svm_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.69239905 0.72066508 0.77173397]\n",
      "Rata Rata Accuracy: 0.73\n",
      "Standar Deviasi: 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "sk_fold = StratifiedKFold(n_splits=3)\n",
    "scores = cross_val_score(svm_model, X, y, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_modelrbf = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "svm_modelrbf.fit(X_train, y_train)\n",
    "svm_predrbf = svm_modelrbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasilrbf = X_test.copy()\n",
    "df_hasilrbf['Label asli'] = y_test.values\n",
    "df_hasilrbf['Label prediksi'] = svm_predrbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       social  finance  health  Label asli  Label prediksi  Prediksi benar\n",
      "9234        0        0       2           1               1            True\n",
      "11965       2        1       1           2               2            True\n",
      "4530        2        1       2           1               1            True\n",
      "11732       2        1       0           0               0            True\n",
      "8441        1        1       0           0               0            True\n",
      "11107       0        0       1           2               2            True\n",
      "7272        0        0       2           2               1           False\n",
      "12532       2        0       1           2               2            True\n",
      "1057        2        1       1           1               2           False\n",
      "1707        1        1       2           1               2           False\n",
      "1817        1        1       0           0               0            True\n",
      "8152        1        1       1           2               2            True\n",
      "10081       0        0       1           2               2            True\n",
      "11493       0        1       2           2               1           False\n",
      "10460       0        0       0           0               0            True\n",
      "12347       1        1       0           0               0            True\n",
      "8591        2        0       0           0               0            True\n",
      "2464        1        1       1           1               2           False\n",
      "5532        1        0       2           1               2           False\n",
      "3324        2        1       2           1               1            True\n",
      "Jumlah hasil prediksi yang benar adalah 1866\n"
     ]
    }
   ],
   "source": [
    "df_hasilrbf['Prediksi benar'] = df_hasilrbf['Label asli'] == df_hasilrbf['Label prediksi']\n",
    "prediksi_benarrbf = df_hasilrbf['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasilrbf.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benarrbf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasilrbf.to_csv('Hasil_prediksiSVM_rbf.csv', index='False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7387173396674585\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       896\n",
      "           1       0.70      0.41      0.51       861\n",
      "           2       0.55      0.81      0.65       769\n",
      "\n",
      "    accuracy                           0.74      2526\n",
      "   macro avg       0.75      0.74      0.72      2526\n",
      "weighted avg       0.76      0.74      0.73      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[896   0   0]\n",
      " [  0 349 512]\n",
      " [  0 148 621]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score: {accuracy_score(y_test, svm_predrbf)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test, svm_predrbf)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, svm_predrbf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.69643705 0.73444181 0.8023753 ]\n",
      "Rata Rata Accuracy: 0.74\n",
      "Standar Deviasi: 0.04\n"
     ]
    }
   ],
   "source": [
    "sk_fold = StratifiedKFold(n_splits=3)\n",
    "scores = cross_val_score(svm_modelrbf, X, y, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Menyimpan model ke pickle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump(svm_model, open('linear_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_linear = pickle.load(open('linear_model', 'rb'))\n",
    "# result_linear = loaded_model_linear.score(X_test, y_test)\n",
    "# print(result_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(svm_modelrbf, open('rbf_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_rbf = pickle.load(open('rbf_model', 'rb'))\n",
    "# result_rbf = loaded_model_rbf.score(X_test, y_test)\n",
    "# print(result_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualisasi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Kurangi dimensi untuk visualisasi (2D) dengan PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "# X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# # Visualisasi SVM pada data training\n",
    "# def plot_pca_decision_boundary(X, y, model):\n",
    "#     x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "#     y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 \n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "#     # Prediksi model pada tiap titik meshgrid\n",
    "#     Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     # Hasil plot area keputusan\n",
    "#     plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
    "\n",
    "#     # Plot data training\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "#     plt.xlabel('Komponen PCA 1') # namanya ganti\n",
    "#     plt.ylabel('Komponen PCA 2')\n",
    "#     plt.title('Visualisasi Batas SVM Dataset Nursery')\n",
    "#     plt.show()\n",
    "\n",
    "# # Panggil fungsi untuk memvisualisasikan dengan model SVM terlatih\n",
    "# plot_pca_decision_boundary(X_train_pca, y_train,svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Kurangi dimensi untuk visualisasi (2D) dengan PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "# X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# # Melatih model SVM dengan kernel RBF\n",
    "# svm_model_rbf = SVC(kernel='rbf', gamma='auto')\n",
    "# svm_model_rbf.fit(X_train, y_train)\n",
    "\n",
    "# # Visualisasi SVM dengan boundary keputusan\n",
    "# def plot_pca_decision_boundary(X, y, model):\n",
    "#     x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "#     y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 \n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "#     # Prediksi model pada tiap titik meshgrid\n",
    "#     Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     # Plot area keputusan\n",
    "#     plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
    "\n",
    "#     # Plot data latih\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.coolwarm)\n",
    "#     plt.xlabel('Komponen PCA 1')\n",
    "#     plt.ylabel('Komponen PCA 2')\n",
    "#     plt.title('Visualisasi Batas Keputusan SVM dengan Kernel RBF')\n",
    "#     plt.show()\n",
    "\n",
    "# # Memanggil fungsi untuk memvisualisasikan dengan model SVM terlatih\n",
    "# plot_pca_decision_boundary(X_train_pca, y_train,svm_modelrbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_ann = y_train.copy()\n",
    "y_train_ann = to_categorical(y_train_ann, num_classes=3)\n",
    "y_test_ann = y_test.copy()\n",
    "y_test_ann = to_categorical(y_test_ann, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi data :\n",
      "\n",
      "X train \t X test \t Y train \t Y test\n",
      "(10104, 3) \t (2526, 3) \t (10104, 3) \t (2526, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensi data :\\n\")\n",
    "print(\"X train \\t X test \\t Y train \\t Y test\")  \n",
    "print(\"%s \\t %s \\t %s \\t %s\" % (X_train.shape, X_test.shape, y_train_ann.shape, y_test_ann.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelANN = Sequential()\n",
    "modelANN.add(Dense(6, activation='relu', input_dim=X_train.shape[1]))\n",
    "modelANN.add(Dense(3, activation='relu'))\n",
    "modelANN.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelANN.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4526 - loss: 1.0675 - val_accuracy: 0.6101 - val_loss: 0.9585\n",
      "Epoch 2/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6253 - loss: 0.8788 - val_accuracy: 0.6823 - val_loss: 0.7290\n",
      "Epoch 3/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6780 - loss: 0.6851 - val_accuracy: 0.6823 - val_loss: 0.6236\n",
      "Epoch 4/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6728 - loss: 0.5945 - val_accuracy: 0.6823 - val_loss: 0.5719\n",
      "Epoch 5/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.5506 - val_accuracy: 0.6823 - val_loss: 0.5434\n",
      "Epoch 6/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6820 - loss: 0.5269 - val_accuracy: 0.6823 - val_loss: 0.5257\n",
      "Epoch 7/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6777 - loss: 0.5096 - val_accuracy: 0.6823 - val_loss: 0.5136\n",
      "Epoch 8/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6757 - loss: 0.4921 - val_accuracy: 0.6823 - val_loss: 0.5048\n",
      "Epoch 9/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.4973 - val_accuracy: 0.6823 - val_loss: 0.4982\n",
      "Epoch 10/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6723 - loss: 0.4837 - val_accuracy: 0.6823 - val_loss: 0.4932\n",
      "Epoch 11/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6666 - loss: 0.4840 - val_accuracy: 0.6823 - val_loss: 0.4893\n",
      "Epoch 12/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.4783 - val_accuracy: 0.6823 - val_loss: 0.4862\n",
      "Epoch 13/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6575 - loss: 0.4778 - val_accuracy: 0.6823 - val_loss: 0.4835\n",
      "Epoch 14/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6695 - loss: 0.4787 - val_accuracy: 0.6823 - val_loss: 0.4814\n",
      "Epoch 15/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.4750 - val_accuracy: 0.6823 - val_loss: 0.4794\n",
      "Epoch 16/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6719 - loss: 0.4718 - val_accuracy: 0.6823 - val_loss: 0.4778\n",
      "Epoch 17/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6703 - loss: 0.4616 - val_accuracy: 0.6823 - val_loss: 0.4764\n",
      "Epoch 18/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.4671 - val_accuracy: 0.6823 - val_loss: 0.4753\n",
      "Epoch 19/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6783 - loss: 0.4623 - val_accuracy: 0.6823 - val_loss: 0.4744\n",
      "Epoch 20/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6752 - loss: 0.4651 - val_accuracy: 0.6823 - val_loss: 0.4735\n",
      "Epoch 21/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6721 - loss: 0.4650 - val_accuracy: 0.6823 - val_loss: 0.4727\n",
      "Epoch 22/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 0.4521 - val_accuracy: 0.6823 - val_loss: 0.4718\n",
      "Epoch 23/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6732 - loss: 0.4608 - val_accuracy: 0.6922 - val_loss: 0.4713\n",
      "Epoch 24/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 0.4588 - val_accuracy: 0.6823 - val_loss: 0.4707\n",
      "Epoch 25/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6788 - loss: 0.4605 - val_accuracy: 0.6823 - val_loss: 0.4704\n",
      "Epoch 26/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6753 - loss: 0.4592 - val_accuracy: 0.6922 - val_loss: 0.4699\n",
      "Epoch 27/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.4618 - val_accuracy: 0.6823 - val_loss: 0.4695\n",
      "Epoch 28/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6778 - loss: 0.4645 - val_accuracy: 0.7185 - val_loss: 0.4675\n",
      "Epoch 29/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7055 - loss: 0.4563 - val_accuracy: 0.7185 - val_loss: 0.4654\n",
      "Epoch 30/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.4568 - val_accuracy: 0.7185 - val_loss: 0.4639\n",
      "Epoch 31/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7192 - loss: 0.4533 - val_accuracy: 0.7185 - val_loss: 0.4628\n",
      "Epoch 32/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 0.4516 - val_accuracy: 0.7264 - val_loss: 0.4634\n",
      "Epoch 33/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7166 - loss: 0.4573 - val_accuracy: 0.7264 - val_loss: 0.4618\n",
      "Epoch 34/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.4441 - val_accuracy: 0.7264 - val_loss: 0.4583\n",
      "Epoch 35/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.4476 - val_accuracy: 0.7264 - val_loss: 0.4577\n",
      "Epoch 36/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.4539 - val_accuracy: 0.7264 - val_loss: 0.4571\n",
      "Epoch 37/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.4518 - val_accuracy: 0.7264 - val_loss: 0.4565\n",
      "Epoch 38/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7154 - loss: 0.4513 - val_accuracy: 0.7264 - val_loss: 0.4562\n",
      "Epoch 39/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.4501 - val_accuracy: 0.7264 - val_loss: 0.4562\n",
      "Epoch 40/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.4433 - val_accuracy: 0.7264 - val_loss: 0.4559\n",
      "Epoch 41/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.4429 - val_accuracy: 0.7239 - val_loss: 0.4550\n",
      "Epoch 42/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.4521 - val_accuracy: 0.7264 - val_loss: 0.4548\n",
      "Epoch 43/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7272 - loss: 0.4457 - val_accuracy: 0.7264 - val_loss: 0.4551\n",
      "Epoch 44/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.4451 - val_accuracy: 0.7264 - val_loss: 0.4547\n",
      "Epoch 45/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.4449 - val_accuracy: 0.7264 - val_loss: 0.4542\n",
      "Epoch 46/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7253 - loss: 0.4482 - val_accuracy: 0.7224 - val_loss: 0.4546\n",
      "Epoch 47/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 0.4479 - val_accuracy: 0.7264 - val_loss: 0.4544\n",
      "Epoch 48/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.4439 - val_accuracy: 0.7264 - val_loss: 0.4539\n",
      "Epoch 49/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.4467 - val_accuracy: 0.7264 - val_loss: 0.4543\n",
      "Epoch 50/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.4447 - val_accuracy: 0.7264 - val_loss: 0.4543\n"
     ]
    }
   ],
   "source": [
    "history = modelANN.fit(X_train, y_train_ann, \n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.4390\n",
      "Test Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelANN.evaluate(X_test, y_test_ann)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ann_predict = modelANN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predict_classes = np.argmax(ann_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [1 2 1 0 0 2 1 2 2 1 0 2 2 1 0 0 0 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions: \", y_predict_classes[:20])  # Tampilkan 10 prediksi pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = np.argmax(y_test_ann, axis=1)\n",
    "y_pred_labels = np.argmax(ann_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasilnn = X_test.copy()\n",
    "df_hasilnn['Label asli'] = y_test_labels\n",
    "df_hasilnn['Label prediksi'] = y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       social  finance  health  Label asli  Label prediksi  Prediksi benar\n",
      "9234        0        0       2           1               1            True\n",
      "11965       2        1       1           2               2            True\n",
      "4530        2        1       2           1               1            True\n",
      "11732       2        1       0           0               0            True\n",
      "8441        1        1       0           0               0            True\n",
      "11107       0        0       1           2               2            True\n",
      "7272        0        0       2           2               1           False\n",
      "12532       2        0       1           2               2            True\n",
      "1057        2        1       1           1               2           False\n",
      "1707        1        1       2           1               1            True\n",
      "1817        1        1       0           0               0            True\n",
      "8152        1        1       1           2               2            True\n",
      "10081       0        0       1           2               2            True\n",
      "11493       0        1       2           2               1           False\n",
      "10460       0        0       0           0               0            True\n",
      "12347       1        1       0           0               0            True\n",
      "8591        2        0       0           0               0            True\n",
      "2464        1        1       1           1               2           False\n",
      "5532        1        0       2           1               1            True\n",
      "3324        2        1       2           1               1            True\n",
      "Jumlah hasil prediksi yang benar adalah 1836\n"
     ]
    }
   ],
   "source": [
    "df_hasilnn['Prediksi benar'] = df_hasilnn['Label asli'] == df_hasilnn['Label prediksi']\n",
    "prediksi_benarnn = df_hasilnn['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasilnn.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benarnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7268408551068883\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       896\n",
      "           1       0.61      0.55      0.58       861\n",
      "           2       0.55      0.60      0.57       769\n",
      "\n",
      "    accuracy                           0.73      2526\n",
      "   macro avg       0.72      0.72      0.72      2526\n",
      "weighted avg       0.73      0.73      0.73      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[896   0   0]\n",
      " [  0 476 385]\n",
      " [  0 305 464]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score: {accuracy_score(y_test_labels, y_pred_labels)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test_labels, y_pred_labels)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test_labels, y_pred_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parents  has_nurs  form  children  housing  finance  social  health  class\n",
       "1        2         3     0         0        0        0       0       1      1\n",
       "2        2         3     0         0        0        0       0       0      0\n",
       "4        2         3     0         0        0        0       2       1      1\n",
       "5        2         3     0         0        0        0       2       0      0\n",
       "6        2         3     0         0        0        0       1       2      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode semua kolom\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*data splitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Training:  (10104, 8)\n",
      "Data Testing:  (2526, 8)\n"
     ]
    }
   ],
   "source": [
    "X2 = df.drop(columns=['class'])  # Semua fitur kecuali 'class'\n",
    "y2 = df['class']                 # Target\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data Training: \", X_train2.shape)\n",
    "print(\"Data Testing: \", X_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*menentukan atribut pca*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.01211225,  1.35549907, -0.71441935],\n",
       "       [-0.99154764, -0.03901466, -0.70322708],\n",
       "       [ 1.01458348,  1.44000872, -0.69603704],\n",
       "       ...,\n",
       "       [ 0.03824963, -1.41810161,  0.64729594],\n",
       "       [ 0.03360286,  0.71860018, -1.44437807],\n",
       "       [-1.96038509, -1.45330404, -0.73407172]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "Xtrain_pca = pca.fit_transform(X_train2)\n",
    "Xtrain_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komponen PCA:\n",
      "[[ 3.18786442e-03  9.99802096e-01  4.40523640e-03 -1.54061168e-02\n",
      "   8.68910076e-03 -5.54472318e-03 -3.30802478e-03 -3.41535458e-03]\n",
      " [ 9.24090640e-04  1.38297082e-02 -7.06784244e-01  7.07016902e-01\n",
      "   1.93611103e-02  5.97462409e-04 -3.93614777e-03  5.61935101e-04]\n",
      " [ 9.44856161e-03  7.75858173e-03  7.06933910e-01  7.06183208e-01\n",
      "   1.32454665e-02 -3.31887679e-04  6.43368556e-03  3.43992445e-02]]\n",
      "Komponen 1:\n",
      "          Komponen 1\n",
      "parents     0.003188\n",
      "has_nurs    0.999802\n",
      "form        0.004405\n",
      "children   -0.015406\n",
      "housing     0.008689\n",
      "finance    -0.005545\n",
      "social     -0.003308\n",
      "health     -0.003415\n",
      "Komponen 2:\n",
      "          Komponen 2\n",
      "parents     0.000924\n",
      "has_nurs    0.013830\n",
      "form       -0.706784\n",
      "children    0.707017\n",
      "housing     0.019361\n",
      "finance     0.000597\n",
      "social     -0.003936\n",
      "health      0.000562\n",
      "Komponen 3:\n",
      "          Komponen 3\n",
      "parents     0.009449\n",
      "has_nurs    0.007759\n",
      "form        0.706934\n",
      "children    0.706183\n",
      "housing     0.013245\n",
      "finance    -0.000332\n",
      "social      0.006434\n",
      "health      0.034399\n"
     ]
    }
   ],
   "source": [
    "# Melihat komponen utama yang dihasilkan oleh PCA\n",
    "print(\"Komponen PCA:\")\n",
    "print(pca.components_)\n",
    "\n",
    "# Jika Anda ingin melihat kontribusi masing-masing fitur pada komponen utama\n",
    "# Kita anggap X_train2 memiliki nama kolom yang representatif\n",
    "feature_names = X_train2.columns  # Nama fitur asli\n",
    "\n",
    "# Menampilkan bobot komponen untuk setiap fitur\n",
    "for i, component in enumerate(pca.components_):\n",
    "    print(f\"Komponen {i + 1}:\")\n",
    "    component_df = pd.DataFrame(component, index=feature_names, columns=[f\"Komponen {i + 1}\"])\n",
    "    print(component_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_pca = pca.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling SVM dengan PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*svm linear*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pcalin_model = SVC(kernel='linear', decision_function_shape='ovo')\n",
    "pcalin_model.fit(Xtrain_pca, y_train2)\n",
    "pcalin_predict = pcalin_model.predict(Xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil_pcalin = pd.DataFrame(Xtest_pca, columns=[f'PC{i+1}' for i in range(Xtest_pca.shape[1])])\n",
    "df_hasil_pcalin['Label asli'] = y_test2.values\n",
    "df_hasil_pcalin['Label prediksi'] = pcalin_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1       PC2       PC3  Label asli  Label prediksi  Prediksi benar\n",
      "0   0.988532 -0.009399  2.113525           1               2           False\n",
      "1  -1.975835 -0.727253 -0.024423           2               1           False\n",
      "2   0.975032  2.123964  0.027953           1               2           False\n",
      "3  -1.985392 -1.473321  0.621620           0               1           False\n",
      "4   2.031313 -1.413375 -0.757448           0               1           False\n",
      "5  -0.972561 -0.725509 -0.042446           2               1           False\n",
      "6  -1.992402  0.675948 -0.007107           2               2            True\n",
      "7   2.031352 -2.125055 -0.018798           2               1           False\n",
      "8  -0.009477  2.129857  0.008489           1               2           False\n",
      "9  -0.000774  0.720787  1.450323           1               2           False\n",
      "10 -0.971744  0.705368 -1.452469           0               1           False\n",
      "11  2.001369  0.727366 -0.004370           2               2            True\n",
      "12  0.016240 -0.711447  1.378430           2               2            True\n",
      "13 -1.970322 -0.738412 -1.429254           2               1           False\n",
      "14 -0.977956  0.687497 -1.490713           0               1           False\n",
      "15  2.041098 -0.668792 -1.447339           0               1           False\n",
      "16  1.987331  0.703142  1.367868           0               2           False\n",
      "17 -0.966349 -0.707639 -0.004201           1               1            True\n",
      "18  0.012583  0.719033  0.028089           1               2           False\n",
      "19 -1.972874 -0.724843  0.028873           1               1            True\n",
      "Jumlah hasil prediksi yang benar adalah 890\n"
     ]
    }
   ],
   "source": [
    "df_hasil_pcalin['Prediksi benar'] = df_hasil_pcalin['Label asli'] == df_hasil_pcalin['Label prediksi']\n",
    "prediksi_benar_pcalin = df_hasil_pcalin['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasil_pcalin.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benar_pcalin}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasil_pcalin.to_csv('Hasil_prediksiSVM_Linear_pca.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.35233570863024544\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       896\n",
      "           1       0.37      0.54      0.43       861\n",
      "           2       0.34      0.56      0.42       769\n",
      "\n",
      "    accuracy                           0.35      2526\n",
      "   macro avg       0.23      0.36      0.29      2526\n",
      "weighted avg       0.23      0.35      0.28      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0 463 433]\n",
      " [  0 463 398]\n",
      " [  0 342 427]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\edwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\edwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test2, pcalin_predict)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test2, pcalin_predict)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test2, pcalin_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.67980998 0.78836105 0.66223278]\n",
      "Rata Rata Accuracy: 0.71\n",
      "Standar Deviasi: 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "sk_fold = StratifiedKFold(n_splits=3)\n",
    "scores = cross_val_score(pcalin_model, X2, y2, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*svm rbf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pcarbf_model = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "pcarbf_model.fit(Xtrain_pca, y_train2)\n",
    "pcarbf_predict = pcarbf_model.predict(Xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil_pcarbf = pd.DataFrame(Xtest_pca, columns=[f'PC{i+1}' for i in range(Xtest_pca.shape[1])])\n",
    "df_hasil_pcarbf['Label asli'] = y_test2.values\n",
    "df_hasil_pcarbf['Label prediksi'] = pcarbf_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1       PC2       PC3  Label asli  Label prediksi  Prediksi benar\n",
      "0   0.988532 -0.009399  2.113525           1               1            True\n",
      "1  -1.975835 -0.727253 -0.024423           2               2            True\n",
      "2   0.975032  2.123964  0.027953           1               1            True\n",
      "3  -1.985392 -1.473321  0.621620           0               2           False\n",
      "4   2.031313 -1.413375 -0.757448           0               2           False\n",
      "5  -0.972561 -0.725509 -0.042446           2               1           False\n",
      "6  -1.992402  0.675948 -0.007107           2               2            True\n",
      "7   2.031352 -2.125055 -0.018798           2               2            True\n",
      "8  -0.009477  2.129857  0.008489           1               1            True\n",
      "9  -0.000774  0.720787  1.450323           1               1            True\n",
      "10 -0.971744  0.705368 -1.452469           0               1           False\n",
      "11  2.001369  0.727366 -0.004370           2               2            True\n",
      "12  0.016240 -0.711447  1.378430           2               1           False\n",
      "13 -1.970322 -0.738412 -1.429254           2               2            True\n",
      "14 -0.977956  0.687497 -1.490713           0               1           False\n",
      "15  2.041098 -0.668792 -1.447339           0               2           False\n",
      "16  1.987331  0.703142  1.367868           0               2           False\n",
      "17 -0.966349 -0.707639 -0.004201           1               1            True\n",
      "18  0.012583  0.719033  0.028089           1               1            True\n",
      "19 -1.972874 -0.724843  0.028873           1               2           False\n",
      "Jumlah hasil prediksi yang benar adalah 1245\n"
     ]
    }
   ],
   "source": [
    "df_hasil_pcarbf['Prediksi benar'] = df_hasil_pcarbf['Label asli'] == df_hasil_pcarbf['Label prediksi']\n",
    "prediksi_benar_pcarbf = df_hasil_pcarbf['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasil_pcarbf.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benar_pcarbf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasil_pcarbf.to_csv('Hasil_prediksiSVM_rbf_pca.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.49287410926365793\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.01      0.02       896\n",
      "           1       0.50      0.77      0.61       861\n",
      "           2       0.49      0.74      0.59       769\n",
      "\n",
      "    accuracy                           0.49      2526\n",
      "   macro avg       0.43      0.51      0.41      2526\n",
      "weighted avg       0.42      0.49      0.39      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 10 479 407]\n",
      " [ 14 664 183]\n",
      " [ 11 187 571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test2, pcarbf_predict)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test2, pcarbf_predict)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test2, pcarbf_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.79952494 0.83016627 0.69904988]\n",
      "Rata Rata Accuracy: 0.78\n",
      "Standar Deviasi: 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "sk_fold = StratifiedKFold(n_splits=3)\n",
    "scores = cross_val_score(pcarbf_model, X2, y2, cv=sk_fold)\n",
    "\n",
    "print(f\"Cross Validation Score: \", scores)\n",
    "print(f\"Rata Rata Accuracy: {scores.mean():.2f}\")\n",
    "print(f\"Standar Deviasi: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling NN dengan PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train2_ann = y_train2.copy()\n",
    "y_train2_ann = to_categorical(y_train2_ann, num_classes=3)\n",
    "y_test2_ann = y_test2.copy()\n",
    "y_test2_ann = to_categorical(y_test2_ann, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Xtrain_pca = np.array(Xtrain_pca)\n",
    "y_train2_ann = np.array(y_train2_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi data :\n",
      "\n",
      "X train \t X test \t Y train \t Y test\n",
      "(10104, 3) \t (2526, 3) \t (10104, 3) \t (2526, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensi data :\\n\")\n",
    "print(\"X train \\t X test \\t Y train \\t Y test\")  \n",
    "print(\"%s \\t %s \\t %s \\t %s\" % (Xtrain_pca.shape, Xtest_pca.shape, y_train2_ann.shape, y_test2_ann.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelANN2 = Sequential()\n",
    "modelANN2.add(Dense(32, activation='relu', input_dim=Xtrain_pca.shape[1]))\n",
    "modelANN2.add(Dense(16, activation='relu'))\n",
    "modelANN2.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelANN2.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> \n",
       "\n",
       " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                        \u001b[38;5;34m128\u001b[0m \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                        \u001b[38;5;34m528\u001b[0m \n",
       "\n",
       " dense_5 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                          \u001b[38;5;34m51\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">707</span> (2.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m707\u001b[0m (2.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">707</span> (2.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m707\u001b[0m (2.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelANN2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3820 - loss: 1.0881 - val_accuracy: 0.4864 - val_loss: 1.0198\n",
      "Epoch 2/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4908 - loss: 1.0080 - val_accuracy: 0.5042 - val_loss: 0.9795\n",
      "Epoch 3/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4926 - loss: 0.9757 - val_accuracy: 0.5151 - val_loss: 0.9704\n",
      "Epoch 4/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5059 - loss: 0.9668 - val_accuracy: 0.5200 - val_loss: 0.9679\n",
      "Epoch 5/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: 0.9618 - val_accuracy: 0.5245 - val_loss: 0.9641\n",
      "Epoch 6/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5010 - loss: 0.9605 - val_accuracy: 0.5082 - val_loss: 0.9630\n",
      "Epoch 7/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5057 - loss: 0.9594 - val_accuracy: 0.5161 - val_loss: 0.9640\n",
      "Epoch 8/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: 0.9603 - val_accuracy: 0.5289 - val_loss: 0.9627\n",
      "Epoch 9/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5098 - loss: 0.9651 - val_accuracy: 0.5151 - val_loss: 0.9622\n",
      "Epoch 10/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.9649 - val_accuracy: 0.5255 - val_loss: 0.9629\n",
      "Epoch 11/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5089 - loss: 0.9617 - val_accuracy: 0.5245 - val_loss: 0.9617\n",
      "Epoch 12/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5088 - loss: 0.9616 - val_accuracy: 0.5176 - val_loss: 0.9610\n",
      "Epoch 13/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5066 - loss: 0.9575 - val_accuracy: 0.5240 - val_loss: 0.9580\n",
      "Epoch 14/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5020 - loss: 0.9612 - val_accuracy: 0.5166 - val_loss: 0.9629\n",
      "Epoch 15/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5030 - loss: 0.9582 - val_accuracy: 0.5250 - val_loss: 0.9589\n",
      "Epoch 16/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5104 - loss: 0.9638 - val_accuracy: 0.5220 - val_loss: 0.9625\n",
      "Epoch 17/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5084 - loss: 0.9624 - val_accuracy: 0.5235 - val_loss: 0.9605\n",
      "Epoch 18/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5024 - loss: 0.9589 - val_accuracy: 0.5146 - val_loss: 0.9598\n",
      "Epoch 19/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5133 - loss: 0.9579 - val_accuracy: 0.5240 - val_loss: 0.9585\n",
      "Epoch 20/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5067 - loss: 0.9551 - val_accuracy: 0.5250 - val_loss: 0.9600\n",
      "Epoch 21/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5114 - loss: 0.9532 - val_accuracy: 0.5245 - val_loss: 0.9556\n",
      "Epoch 22/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5055 - loss: 0.9619 - val_accuracy: 0.5230 - val_loss: 0.9602\n",
      "Epoch 23/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.9587 - val_accuracy: 0.5151 - val_loss: 0.9585\n",
      "Epoch 24/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 0.9568 - val_accuracy: 0.5225 - val_loss: 0.9576\n",
      "Epoch 25/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5079 - loss: 0.9592 - val_accuracy: 0.5195 - val_loss: 0.9609\n",
      "Epoch 26/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5070 - loss: 0.9553 - val_accuracy: 0.5240 - val_loss: 0.9585\n",
      "Epoch 27/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5016 - loss: 0.9616 - val_accuracy: 0.5255 - val_loss: 0.9586\n",
      "Epoch 28/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5060 - loss: 0.9651 - val_accuracy: 0.5230 - val_loss: 0.9565\n",
      "Epoch 29/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5047 - loss: 0.9621 - val_accuracy: 0.5245 - val_loss: 0.9574\n",
      "Epoch 30/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: 0.9607 - val_accuracy: 0.5250 - val_loss: 0.9560\n",
      "Epoch 31/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5074 - loss: 0.9578 - val_accuracy: 0.5265 - val_loss: 0.9582\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "# Early stopping callback \n",
    "earlyStop = EarlyStopping(monitor='val_loss', \n",
    "                          mode='min', \n",
    "                          patience=10, \n",
    "                          restore_best_weights=True) \n",
    "\n",
    "# Train the model with early stopping \n",
    "history2 = modelANN2.fit(Xtrain_pca, y_train2_ann, \n",
    "                         callbacks=[earlyStop], \n",
    "                         epochs=50, \n",
    "                         batch_size=32, \n",
    "                         shuffle=True, \n",
    "                         validation_split=0.2, \n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4882 - loss: 0.9605\n",
      "Test Accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelANN2.evaluate(Xtest_pca, y_test2_ann)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ann2_predict = modelANN2.predict(Xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predict2_classes = np.argmax(ann2_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [1 2 1 2 2 0 2 2 1 1 1 2 1 2 1 2 2 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions: \", y_predict2_classes[:20])  # Tampilkan 10 prediksi pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2_labels = np.argmax(y_test2_ann, axis=1)\n",
    "y_pred2_labels = np.argmax(ann2_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_test2_labels = pd.Series(y_test2_labels)\n",
    "y_pred2_labels = pd.Series(y_pred2_labels)\n",
    "\n",
    "Xtest_pca = pd.DataFrame(Xtest_pca)\n",
    "df_hasilnn2 = Xtest_pca.copy()\n",
    "df_hasilnn2['Label asli'] = y_test2_labels\n",
    "df_hasilnn2['Label prediksi'] = y_pred2_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2  Label asli  Label prediksi  Prediksi benar\n",
      "0   0.988532 -0.009399  2.113525           1               1            True\n",
      "1  -1.975835 -0.727253 -0.024423           2               2            True\n",
      "2   0.975032  2.123964  0.027953           1               1            True\n",
      "3  -1.985392 -1.473321  0.621620           0               2           False\n",
      "4   2.031313 -1.413375 -0.757448           0               2           False\n",
      "5  -0.972561 -0.725509 -0.042446           2               0           False\n",
      "6  -1.992402  0.675948 -0.007107           2               2            True\n",
      "7   2.031352 -2.125055 -0.018798           2               2            True\n",
      "8  -0.009477  2.129857  0.008489           1               1            True\n",
      "9  -0.000774  0.720787  1.450323           1               1            True\n",
      "10 -0.971744  0.705368 -1.452469           0               1           False\n",
      "11  2.001369  0.727366 -0.004370           2               2            True\n",
      "12  0.016240 -0.711447  1.378430           2               1           False\n",
      "13 -1.970322 -0.738412 -1.429254           2               2            True\n",
      "14 -0.977956  0.687497 -1.490713           0               1           False\n",
      "15  2.041098 -0.668792 -1.447339           0               2           False\n",
      "16  1.987331  0.703142  1.367868           0               2           False\n",
      "17 -0.966349 -0.707639 -0.004201           1               0           False\n",
      "18  0.012583  0.719033  0.028089           1               1            True\n",
      "19 -1.972874 -0.724843  0.028873           1               2           False\n",
      "Jumlah hasil prediksi yang benar adalah 1247\n"
     ]
    }
   ],
   "source": [
    "df_hasilnn2['Prediksi benar'] = df_hasilnn2['Label asli'] == df_hasilnn2['Label prediksi']\n",
    "prediksi_benarnn2 = df_hasilnn2['Prediksi benar'].sum()\n",
    "\n",
    "print(df_hasilnn2.head(20))\n",
    "print(f'Jumlah hasil prediksi yang benar adalah {prediksi_benarnn2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hasilnn2.to_csv('Hasil_prediksiNN_pca.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.4936658749010293\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.06      0.10       896\n",
      "           1       0.51      0.75      0.61       861\n",
      "           2       0.49      0.72      0.59       769\n",
      "\n",
      "    accuracy                           0.49      2526\n",
      "   macro avg       0.45      0.51      0.43      2526\n",
      "weighted avg       0.45      0.49      0.42      2526\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 52 453 391]\n",
      " [ 45 644 172]\n",
      " [ 56 162 551]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score: {accuracy_score(y_test2_labels, y_pred2_labels)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test2_labels, y_pred2_labels)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test2_labels, y_pred2_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model Terbaik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari keempat algoritma yang dicobakan, yaitu:\n",
    "1. SVM Tanpa PCA\n",
    "2. SVM dengan PCA\n",
    "3. Neural Network Tanpa PCA\n",
    "4. Neural Network dengan PCA\n",
    "\n",
    "Model yang menghasilkan akurasi terbaik adalah **SVM RBF tanpa PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(svm_modelrbf, open('rbf_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_rbf = pickle.load(open('rbf_model', 'rb'))\n",
    "result_rbf = loaded_model_rbf.score(X_test, y_test)\n",
    "print(result_rbf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
